"""
AI Chat Assistant Frontend
Streamlit UI for chatting with Gemini AI
"""

import streamlit as st
import requests
from datetime import datetime
import time

# Sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(
    page_title="AI Chat Assistant",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Backend API URL'i
BACKEND_URL = "http://backend:8000"

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .user-message {
        background-color: #e3f2fd;
        margin-left: 2rem;
    }
    .assistant-message {
        background-color: #f5f5f5;
        margin-right: 2rem;
    }
    .stButton>button {
        width: 100%;
        background-color: #1f77b4;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# Session state'i baÅŸlat
if "messages" not in st.session_state:
    st.session_state.messages = []

if "backend_status" not in st.session_state:
    st.session_state.backend_status = "checking"

# Backend saÄŸlÄ±k kontrolÃ¼
def check_backend_health():
    try:
        response = requests.get(f"{BACKEND_URL}/health", timeout=5)
        if response.status_code == 200:
            data = response.json()
            return data.get("status"), data.get("message")
        return "error", "Backend'e ulaÅŸÄ±lamÄ±yor"
    except Exception as e:
        return "error", f"BaÄŸlantÄ± hatasÄ±: {str(e)}"

# Mesaj gÃ¶nder
def send_message(message, temperature, max_tokens):
    try:
        # Sohbet geÃ§miÅŸini hazÄ±rla
        chat_history = [
            {"role": msg["role"], "content": msg["content"]} 
            for msg in st.session_state.messages
        ]
        
        # API'ye istek gÃ¶nder
        response = requests.post(
            f"{BACKEND_URL}/chat",
            json={
                "message": message,
                "chat_history": chat_history,
                "temperature": temperature,
                "max_tokens": max_tokens
            },
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            return data.get("response"), None
        else:
            return None, f"API HatasÄ±: {response.status_code}"
    
    except Exception as e:
        return None, f"Ä°stek hatasÄ±: {str(e)}"

# Ana baÅŸlÄ±k
st.markdown('<h1 class="main-header">ğŸ¤– AI Chat Assistant</h1>', unsafe_allow_html=True)
st.markdown("---")

# Sidebar - Ayarlar
with st.sidebar:
    st.header("âš™ï¸ Ayarlar")
    
    # Backend durumu
    status, message = check_backend_health()
    if status == "healthy":
        st.success(f"âœ… {message}")
    else:
        st.error(f"âŒ {message}")
    
    st.markdown("---")
    
    # AI Parametreleri
    st.subheader("ğŸ›ï¸ AI Parametreleri")
    
    temperature = st.slider(
        "Temperature (YaratÄ±cÄ±lÄ±k)",
        min_value=0.0,
        max_value=2.0,
        value=0.7,
        step=0.1,
        help="DÃ¼ÅŸÃ¼k deÄŸer: Daha tutarlÄ±, YÃ¼ksek deÄŸer: Daha yaratÄ±cÄ±"
    )
    
    max_tokens = st.slider(
        "Maksimum Token (Cevap UzunluÄŸu)",
        min_value=100,
        max_value=2000,
        value=1000,
        step=100,
        help="AI'Ä±n Ã¼retebileceÄŸi maksimum kelime sayÄ±sÄ±"
    )
    
    st.markdown("---")
    
    # Sohbet geÃ§miÅŸini temizle
    if st.button("ğŸ—‘ï¸ Sohbeti Temizle"):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    
    # Bilgi
    with st.expander("â„¹ï¸ HakkÄ±nda"):
        st.write("""
        **AI Chat Assistant**
        
        Bu uygulama GÃ¶rkem Sayer'in webinar'Ä±nda 
        Ã¶ÄŸrenilen teknolojilerle yapÄ±lmÄ±ÅŸtÄ±r:
        
        - ğŸš€ FastAPI
        - ğŸ¨ Streamlit
        - ğŸ³ Docker
        - ğŸ¤– Google Gemini AI
        
        **KullanÄ±m:**
        1. SaÄŸ tarafta mesaj yazÄ±n
        2. GÃ¶nder'e basÄ±n
        3. AI'Ä±n cevabÄ±nÄ± gÃ¶rÃ¼n
        
        **Ä°pucu:** Temperature deÄŸerini 
        ayarlayarak AI'Ä±n cevap stilini 
        deÄŸiÅŸtirebilirsiniz!
        """)

# Ana alan - Chat
st.subheader("ğŸ’¬ Sohbet")

# Mesaj geÃ§miÅŸini gÃ¶ster
chat_container = st.container()
with chat_container:
    for message in st.session_state.messages:
        if message["role"] == "user":
            st.markdown(f"""
            <div class="chat-message user-message">
                <strong>ğŸ‘¤ Sen:</strong><br>
                {message["content"]}
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="chat-message assistant-message">
                <strong>ğŸ¤– AI Assistant:</strong><br>
                {message["content"]}
            </div>
            """, unsafe_allow_html=True)

# Mesaj input alanÄ±
st.markdown("---")
col1, col2 = st.columns([6, 1])

with col1:
    user_input = st.text_input(
        "MesajÄ±nÄ±zÄ± yazÄ±n:",
        key="user_input",
        placeholder="AI'a bir ÅŸey sorun...",
        label_visibility="collapsed"
    )

with col2:
    send_button = st.button("ğŸ“¤ GÃ¶nder", use_container_width=True)

# Mesaj gÃ¶nderme iÅŸlemi
if send_button and user_input:
    # KullanÄ±cÄ± mesajÄ±nÄ± ekle
    st.session_state.messages.append({
        "role": "user",
        "content": user_input,
        "timestamp": datetime.now().isoformat()
    })
    
    # Loading gÃ¶ster
    with st.spinner("ğŸ¤” AI dÃ¼ÅŸÃ¼nÃ¼yor..."):
        response, error = send_message(user_input, temperature, max_tokens)
    
    if error:
        st.error(f"âŒ Hata: {error}")
    else:
        # AI cevabÄ±nÄ± ekle
        st.session_state.messages.append({
            "role": "assistant",
            "content": response,
            "timestamp": datetime.now().isoformat()
        })
    
    # SayfayÄ± yenile
    st.rerun()

# Sayfa altÄ±
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray; font-size: 0.8rem;'>
    Made with â¤ï¸ using FastAPI, Streamlit & Docker | 
    Powered by Google Gemini AI
</div>
""", unsafe_allow_html=True)
